normalize,False
agent0_layer_sizes,[256, 128]
complete_episodes,15001
num_episodes,15000
agent1_state_dimension,21
wall_bonus,-0.0625
agent1_action_options,[[ 1 -1]
 [ 1  1]]
num_steps,160
door_bonus,0
agent0_learning_rate,0.001
agent0_action_options,[[ 1 -1]
 [ 1  1]]
source,
agent1_layer_sizes,[256, 128]
success_count,4249
agent1_learning_rate,0.001
complete_steps,397513
agent0_state_dimension,21
success_bonus,1.0
time_bonus,-0.00625
train_dur,119487.941919
