normalize,False
agent0_layer_sizes,[256, 128]
complete_episodes,10001
num_episodes,10000
agent1_state_dimension,21
wall_bonus,-0.05
agent1_action_options,[[ 1 -1]
 [ 1  1]]
num_steps,200
door_bonus,-0.05
agent0_learning_rate,0.001
agent0_action_options,[[ 1 -1]
 [ 1  1]]
source,
agent1_layer_sizes,[256, 128]
success_count,2667
agent1_learning_rate,0.001
complete_steps,279665
agent0_state_dimension,21
success_bonus,1.0
time_bonus,-0.005
train_dur,82973.110045
